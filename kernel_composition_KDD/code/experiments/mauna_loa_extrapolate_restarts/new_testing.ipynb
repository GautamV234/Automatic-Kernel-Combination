{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/gautam.pv/miniconda3/envs/akc_env_kkd/lib/python3.10/site-packages/torch/lib/libtorch_cuda_cpp.so: undefined symbol: cudaGraphRetainUserObject, version libcudart.so.11.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgpytorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# create a simple 1 d regression dataset for GP Regresssion\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/akc_env_kkd/lib/python3.10/site-packages/gpytorch/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#!/usr/bin/env python3\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Optional, Tuple, Union\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlinear_operator\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlinear_operator\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearOperator\n",
      "File \u001b[0;32m~/miniconda3/envs/akc_env_kkd/lib/python3.10/site-packages/linear_operator/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#!/usr/bin/env python3\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m beta_features, operators, settings, utils\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfunctions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     add_diagonal,\n\u001b[1;32m      5\u001b[0m     add_jitter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     sqrt_inv_matmul,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39moperators\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearOperator, to_dense, to_linear_operator\n",
      "File \u001b[0;32m~/miniconda3/envs/akc_env_kkd/lib/python3.10/site-packages/linear_operator/beta_features.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#!/usr/bin/env python3\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msettings\u001b[39;00m \u001b[39mimport\u001b[39;00m _feature_flag\n\u001b[1;32m      8\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_moved_beta_feature\u001b[39;00m(\u001b[39mobject\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, new_cls, orig_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/akc_env_kkd/lib/python3.10/site-packages/linear_operator/settings.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_dtype_value_context\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     _global_float_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/akc_env_kkd/lib/python3.10/site-packages/torch/__init__.py:218\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[39mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    217\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39m# torch._C module initialization code in C\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mImportError\u001b[0m: /home/gautam.pv/miniconda3/envs/akc_env_kkd/lib/python3.10/site-packages/torch/lib/libtorch_cuda_cpp.so: undefined symbol: cudaGraphRetainUserObject, version libcudart.so.11.0"
     ]
    }
   ],
   "source": [
    "import gpytorch\n",
    "# create a simple 1 d regression dataset for GP Regresssion\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import gpytorch\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "y = np.sin(x * (2 * np.pi)) + np.random.randn(100) * 0.2\n",
    "x = x.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=False)\n",
    "x_train = torch.from_numpy(x_train).float().squeeze()\n",
    "y_train = torch.from_numpy(y_train).float().squeeze()\n",
    "x_test = torch.from_numpy(x_test).float().squeeze()\n",
    "y_test = torch.from_numpy(y_test).float().squeeze()\n",
    "\n",
    "#  create a gpytorch model \n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        # inner_kernel = (gpytorch.kernels.MaternKernel(nu=1.5) + gpytorch.kernels.RQKernel())*gpytorch.kernels.PeriodicKernel()\n",
    "        # self.covar_module = gpytorch.kernels.ScaleKernel(inner_kernel)\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = self.mean_module(x)\n",
    "        covar = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean, covar)\n",
    "# train this using lbfgs optimizer\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(x_train, y_train, likelihood)\n",
    "model.train()\n",
    "likelihood.train()\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=0.1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x_train)\n",
    "    loss = -mll(output, y_train)\n",
    "    return loss\n",
    "losses = []\n",
    "for i in range(100):\n",
    "    loss = closure()\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, 100, loss.item()))\n",
    "    optimizer.step(closure)\n",
    "# test the model\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred = likelihood(model(x_test))\n",
    "    mean = observed_pred.mean\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "# plot the results\n",
    "f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "ax.plot(x_train.numpy(), y_train.numpy(), 'k*')\n",
    "ax.plot(x_test.numpy(), y_test.numpy(), 'b')\n",
    "ax.plot(x_test.numpy(), mean.numpy(), 'r')\n",
    "ax.fill_between(x_test.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "\n",
    "# compare this result against adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x_train)\n",
    "    loss = -mll(output, y_train)\n",
    "    return loss\n",
    "losses = []\n",
    "for i in range(100):\n",
    "    loss = closure()\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, 100, loss.item()))\n",
    "    optimizer.step(closure)\n",
    "# test the model\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use periodic * RBF kernel and do not train on the periodic kernel and set its period to 2\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        inner_kernel = gpytorch.kernels.RBFKernel()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(inner_kernel)\n",
    "        self.covar_module.base_kernel.period_length.requires_grad = False\n",
    "        self.covar_module.base_kernel.period_length = 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = self.mean_module(x)\n",
    "        covar = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean, covar)\n",
    "# train this using lbfgs optimizer\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(x_train, y_train, likelihood)\n",
    "model.train()\n",
    "likelihood.train()\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=0.1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x_train)\n",
    "    loss = -mll(output, y_train)\n",
    "    return loss\n",
    "losses = []\n",
    "for i in range(100):\n",
    "    loss = closure()\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, 100, loss.item()))\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lbfgs to train a GP Regression model using GPYtorch\n",
    "# initialize the model\n",
    "# initialize the likelihood\n",
    "likelihood = GaussianLikelihood()\n",
    "model = ExactGPModel(torch.from_numpy(x).float().unsqueeze(-1), torch.from_numpy(y).float().unsqueeze(-1), likelihood)\n",
    "# Find optimal model hyperparameters\n",
    "# Use the adam optimizer\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "# Defines the model and likelihood\n",
    "model.train()\n",
    "likelihood.train()\n",
    "# Use the LBFGS optimizer\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=0.1)\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "# Define training iterations\n",
    "training_iter = 100\n",
    "for i in range(training_iter):\n",
    "    # Zero backpropped gradients from previous iteration\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        return loss\n",
    "    loss = optimizer.step(closure)\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iter, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akc_env_kkd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ac90ba00bc655bf124af03dfb1487b3a1bada0c5e03441f9d0354d02b55eb66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
